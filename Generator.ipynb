{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, CuDNNLSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Text and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scripts = \"\"\n",
    "def TextToString(txt):\n",
    "    with open(txt, \"r\") as file:\n",
    "        data = file.readlines()\n",
    "        script = \"\"\n",
    "        for x in data[1:-1]:\n",
    "            x = x.lower()\n",
    "            x = x.replace('\"', '')\n",
    "            x = x.replace(\"\\n\", \" \\n \")\n",
    "            x = x.split(' ')\n",
    "            x[1] += \":\"\n",
    "            script += \" \".join(x[1:-1]).replace(\"\\n\", \" \\n \")\n",
    "        return script\n",
    "\n",
    "Scripts += TextToString(\"datasets/SW_EpisodeIV.txt\")\n",
    "Scripts += TextToString(\"datasets/SW_EpisodeV.txt\")\n",
    "Scripts += TextToString(\"datasets/SW_EpisodeVI.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threepio: did you hear that?  they've shut down the main reactor.  we'll be destroyed for sure.  this is madness!  \n",
      " threepio: we're doomed!  \n",
      " threepio: there'll be no escape for the princess this time.  \n",
      " threepio: what's that?  \n",
      " threepio: i should have known better than to trust the logic of a half-sized thermocapsulary dehousing assister...  \n",
      " luke: hurry up!  come with me!  what are you waiting for?!  get in gear!  \n",
      " threepio: artoo! artoo-detoo, where are you?  \n",
      " threepio: at last!  where have you been?  \n",
      " threepio: they're heading in this direction. what are we going to do?  we'll be sent to the spice mines of kessel or smashed into who knows what!  \n",
      " threepio: wait a minute, where are you going?  \n",
      " imperial: officer the death star plans are not in the main computer.  \n",
      " vader: where are those transmissions you intercepted?  \n",
      " rebel: officer we intercepted no transmissions. aaah...  this is a consular ship. were on a diplomatic mission.  \n",
      " vader: if this is a consular ship... wh\n"
     ]
    }
   ],
   "source": [
    "print(Scripts[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '#', \"'\", ',', '-', '.', '/', '0', '1', '2', '3', '4', '6', '7', '8', ':', ';', '?', '\\\\', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "text_data = Scripts\n",
    "\n",
    "charindex = list(set(text_data))\n",
    "charindex.sort()\n",
    "\n",
    "print(charindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_size = len(charindex)\n",
    "sequence_length = 100\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for i in range(0, len(text_data) - sequence_length, 1):\n",
    "    X = text_data[i:i + sequence_length]\n",
    "    Y = text_data[i + sequence_length]\n",
    "    X_train.append([charindex.index(x) for x in X])\n",
    "    Y_train.append(charindex.index(Y))\n",
    "\n",
    "X_train = np.reshape(X_train, (len(X_train), sequence_length))\n",
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(sequence_length, )))\n",
    "model.add(Embedding(char_size, 100))\n",
    "model.add(CuDNNLSTM(512, return_sequences=True))\n",
    "model.add(CuDNNLSTM(256, return_sequences=True))\n",
    "model.add(CuDNNLSTM(128))\n",
    "model.add(Dense(256, activation='elu'))\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(Dense(char_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    Y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=100,\n",
    "                    verbose=1)\n",
    "\n",
    "model.save_weights('weight.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "text_length = 5000\n",
    "x = np.random.randint(0, len(X_train)-1)\n",
    "pattern = X_train[x]\n",
    "\n",
    "output = []\n",
    "for t in tqdm(range(text_length)):\n",
    "    x = np.reshape(pattern, (1, len(pattern)))\n",
    "    prediction = model.predict(x)\n",
    "    result = np.argmax(prediction)\n",
    "    output.append(result)\n",
    "    pattern = np.append(pattern, result)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [charindex[x] for x in output]\n",
    "output = ''.join(output)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
